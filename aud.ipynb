{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at fractalego/personal-speech-to-text-model were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at fractalego/personal-speech-to-text-model and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"fractalego/personal-speech-to-text-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model directly\n",
    "# from transformers import AutoProcessor, AutoModelForCTC\n",
    "\n",
    "# processor = AutoProcessor.from_pretrained(\"fractalego/personal-speech-to-text-model\")\n",
    "# model = AutoModelForCTC.from_pretrained(\"fractalego/personal-speech-to-text-model\")\n",
    "\n",
    "import ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at fractalego/personal-speech-to-text-model were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at fractalego/personal-speech-to-text-model and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': \"HELLO EVERYONE THANK YOU GUYS FOR COMING TO OUR WEEKLY STUDENT SUCCESS MEETING UM AND LET'S JUST GET STARTED SO I HAVE OUR LIST OF CRONICALY ABSENTE STUDENTS HERE AND I'VE BEEN NOTICING A TROUBLING TREND UM A LOT OF STUDENTS ARE SKIPPING ON FRIDAYS DOES ANYONE HAVE ANY IDEA WHAT'S GOING ON I'VE HEARD SOME OF MY MENTIS TALKING ABOUT HOW IT'S REALLY HARD TO GET OUT OF BED ON FRIDAYS IT MIGHT BE GOOD IF WE DID SOMETHING LIKE A PANCAKE BREAKFAST TO ENCOURAGE THEM TO COMEI THINK THAT'S A GREA'S NEXWEEK IT MIGHT ALSO BE BECAUSE A LOT OF STUDENTS HAVE BEEN GETTING SICK NOW THAT IT'S GETTING COLDER OUTSIDE I'VE HAD A NUMBER OF STUDENTS COME BY MY OFFICE WITH SYMPTOMS LIKE SNIFFLING IN CATHE WE SHOULD PUT UP POSTERS WITH TAPS FOR KNOTGETTINGS SICK SINCE IT'S ALMOST FLEASEEASON LIKE YOU KNOW WASH OUR HANDS AFTER THE BATHROOM STUFF LIKE THAT I THINK THAT'S A GOOD IDEA AND IT'LL BE A GOOD REMINDER FOR THE TEACHERS AS WELLTO ONE OTHER THING I WANT TO TALK ABOUT UM THERE'S A STUDENT I'VE NOTICED HERE JOHN SMITH HE'S MISSED SEVEN DAYS ALREADY AND IT'S ONLY NOVEMBER DOES ANYONE HAVE AN IDEA WHAT'S GOING ON WITH HIM I MIGHT BE ABLE TO FILL IN THE GAPS THERE I TALKED TO JON TODAY AND HE'S REALLY THRESSED OUT HE'S BEEN DEALING WITH HELPING HIS PARENTS TAKE CARE OF HIS YOUNGER SIBLINGS DURING THE DAY UM IT MIGHT ACTUALLY BE A GOOD IDEA IF HE SPOKE TO THE GUIDANCE COUNSELER A LITTLE BIT I CAN TALK TO JON TODAY IF YOU WANT TO SEND HMM TO MY OFFICE AFTER YOU MEE WITH HIMIT'S A LOT TO DEAL WITH FOR A MIDDLE SCHOOLER GREAT THANKS AND AND I CAN HELP OUT WITH THE FAMILYS CHILD CARE NEEDS UH I'LL LOOK FOR SOME FREE OR LOW COST RESOURCES IN THE COMMUNITY TO SHARE WITH JON AND HE CAN SHARE THEM WITH HIS FAMILYGREAT WELL SOME REALLY GOOD IDEAS HERE TODAY UM THANKS FOR COMING AND IF NOONE HAS ANYTHING ELSE I THINK WE CAN WRAP UP\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"fractalego/personal-speech-to-text-model\")\n",
    "pipe(\"Weekly Meeting Example.mp3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
